{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv files to pandas data frames\n",
    "train_data = pd.DataFrame(pd.read_csv('./input/train.csv'))\n",
    "test_data = pd.DataFrame(pd.read_csv('./input/test.csv'))\n",
    "data = [train_data, test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set in data:\n",
    "    # checking for missing values\n",
    "    m_values = set.isnull().sum()\n",
    "    if m_values.sum()==0:\n",
    "        print ('No missing values found in dataset.')\n",
    "    else:\n",
    "        for i in range(len(m_values)):\n",
    "            if m_values.data[i] != 0:\n",
    "                print ('Column {} has {} missing values'.format(m_values.index[i], m_values.data[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the correlation matrix\n",
    "corr = train_data.corr()\n",
    "frame, heatmap = plt.subplots()\n",
    "# adding correlation data\n",
    "heatmap.imshow(corr, cmap='inferno')\n",
    "# setting x,y axes ticks\n",
    "heatmap.set_xticks(np.arange(train_data.columns.size))\n",
    "heatmap.set_yticks(np.arange(train_data.columns.size))\n",
    "# setting x.y axes labels\n",
    "heatmap.set_xticklabels(train_data.columns)\n",
    "heatmap.set_yticklabels(train_data.columns)\n",
    "# rotating x axes labels by 45 degrees for convenience\n",
    "plt.setp(heatmap.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "# tight layout\n",
    "frame.tight_layout\n",
    "# plotting the heat map\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping Total Volume Donated (c.c.) column as it shows the strongest linear relationship with Number of Donations\n",
    "train_data.drop(columns=['Total Volume Donated (c.c.)'], inplace=True)\n",
    "test_data.drop(columns=['Total Volume Donated (c.c.)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 'Days since First Donation' and 'Days since Last Donation' features\n",
    "train_data = train_data.rename({'Months since Last Donation':'Days since Last Donation'}, axis='columns')\n",
    "train_data = train_data.rename({'Months since First Donation':'Days since First Donation'}, axis='columns')\n",
    "\n",
    "train_data['Days since First Donation'] = train_data['Days since First Donation'].apply(lambda x: x*30)\n",
    "train_data['Days since Last Donation'] = train_data['Days since Last Donation'].apply(lambda x: x*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate the mean time period between two donations in days\n",
    "mean_wait = np.mean((train_data['Days since First Donation'] - train_data['Days since Last Donation'])/train_data['Number of Donations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add donation eligibility. True if Days since last donation > 60, False otherwise.\n",
    "eligibility_vector = pd.DataFrame([(np.array(train_data['Days since First Donation']) > 60).T],columns=['Donation Eligiblity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add donation likelihood\n",
    "likelihood_vector = pd.DataFrame([(np.array((train_data['Days since First Donation'] - train_data['Days since Last Donation'])/train_data['Number of Donations']) > mean_wait).T], columns=['Donation Likelihood'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new vectors to the original dataset\n",
    "train_data = pd.DataFrame([pd.DataFrame.concat([train_data, eligibility_vector], axis=1), likelihood_vector], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('processed_input/train.csv')\n",
    "test_data.to_csv('processed_input/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
